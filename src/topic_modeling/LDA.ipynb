{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/diegojimenez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/diegojimenez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/diegojimenez/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_numeric\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Link</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>China says it’s building new homegrown aircraf...</td>\n",
       "      <td>Updated 1:09 PM EST, Fri January 1, 2016</td>\n",
       "      <td>Story highlights The U.S. military has long be...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2015/12/31/asia/china-...</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hillary Clinton emails: Kissinger, Photoshop a...</td>\n",
       "      <td>Updated 9:34 PM EST, Thu December 31, 2015</td>\n",
       "      <td>Story highlights The State Department released...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2015/12/31/politics/cl...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How the stars rang in 2016</td>\n",
       "      <td>Published 9:04 AM EST, Fri January 1, 2016</td>\n",
       "      <td>Story highlights Some stars hit exotic locatio...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2016/01/01/entertainme...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Smoke still wafting from Dubai’s luxury Addres...</td>\n",
       "      <td>Updated 4:55 PM EST, Fri January 1, 2016</td>\n",
       "      <td>Story highlights NEW: Fire has been contained ...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2016/01/01/middleeast/...</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Super PACs backing Cruz to launch TV ad blitz</td>\n",
       "      <td>Published 8:36 PM EST, Thu December 31, 2015</td>\n",
       "      <td>Story highlights Ads supporting Cruz set to ai...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2015/12/31/politics/cr...</td>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Headline  \\\n",
       "0   1  China says it’s building new homegrown aircraf...   \n",
       "1   2  Hillary Clinton emails: Kissinger, Photoshop a...   \n",
       "2   3                         How the stars rang in 2016   \n",
       "3   4  Smoke still wafting from Dubai’s luxury Addres...   \n",
       "4   5      Super PACs backing Cruz to launch TV ad blitz   \n",
       "\n",
       "                                           Date  \\\n",
       "0      Updated 1:09 PM EST, Fri January 1, 2016   \n",
       "1    Updated 9:34 PM EST, Thu December 31, 2015   \n",
       "2    Published 9:04 AM EST, Fri January 1, 2016   \n",
       "3      Updated 4:55 PM EST, Fri January 1, 2016   \n",
       "4  Published 8:36 PM EST, Thu December 31, 2015   \n",
       "\n",
       "                                                Text Organization  \\\n",
       "0  Story highlights The U.S. military has long be...          CNN   \n",
       "1  Story highlights The State Department released...          CNN   \n",
       "2  Story highlights Some stars hit exotic locatio...          CNN   \n",
       "3  Story highlights NEW: Fire has been contained ...          CNN   \n",
       "4  Story highlights Ads supporting Cruz set to ai...          CNN   \n",
       "\n",
       "                                                Link  Cluster  \n",
       "0  https://edition.cnn.com/2015/12/31/asia/china-...      619  \n",
       "1  https://edition.cnn.com/2015/12/31/politics/cl...       -1  \n",
       "2  https://edition.cnn.com/2016/01/01/entertainme...       -1  \n",
       "3  https://edition.cnn.com/2016/01/01/middleeast/...      482  \n",
       "4  https://edition.cnn.com/2015/12/31/politics/cr...     1428  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/Users/diegojimenez/Documents/GitHub/computational_ds/data/output/updated_dataframe_with_clusters_word2vec.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446967"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text has been added to the DataFrame and saved to 'cleaned_dataframe.csv'\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(df, text_column, custom_stopwords):\n",
    "    clean_text_column = f\"{text_column}_cleaned\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_single_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return []\n",
    "\n",
    "        text = text.lower()\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token for token in tokens if token not in custom_stopwords]\n",
    "        tokens = [token for token in tokens if token.isalpha()]\n",
    "        tokens = [token for token in tokens if not token.isdigit()]\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    # Apply the cleaning function to the specified column\n",
    "    df[clean_text_column] = df[text_column].apply(clean_single_text)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Define your custom stopwords and stop words\n",
    "custom_stopwords = [\"reuters\", \"fox\", \"cnn\", \"was\", \"has\", \"us\", \"year\"]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Call the function and update the DataFrame\n",
    "df_final = preprocess_text(df, \"Text\", custom_stopwords)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_final.to_csv('cleaned_dataframe.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Cleaned text has been added to the DataFrame and saved to 'cleaned_dataframe.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=pd.read_csv(\"/Users/diegojimenez/Documents/GitHub/computational_ds/src/topic_modeling/cleaned_dataframe.csv\")\n",
    "df_final[\"Text_cleaned\"] = df_final[\"Text_cleaned\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Link</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>China says it’s building new homegrown aircraf...</td>\n",
       "      <td>Updated 1:09 PM EST, Fri January 1, 2016</td>\n",
       "      <td>Story highlights The U.S. military has long be...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2015/12/31/asia/china-...</td>\n",
       "      <td>619</td>\n",
       "      <td>[story, highlight, military, long, believed, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hillary Clinton emails: Kissinger, Photoshop a...</td>\n",
       "      <td>Updated 9:34 PM EST, Thu December 31, 2015</td>\n",
       "      <td>Story highlights The State Department released...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2015/12/31/politics/cl...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[story, highlight, state, department, released...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How the stars rang in 2016</td>\n",
       "      <td>Published 9:04 AM EST, Fri January 1, 2016</td>\n",
       "      <td>Story highlights Some stars hit exotic locatio...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2016/01/01/entertainme...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[story, highlight, star, hit, exotic, location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Smoke still wafting from Dubai’s luxury Addres...</td>\n",
       "      <td>Updated 4:55 PM EST, Fri January 1, 2016</td>\n",
       "      <td>Story highlights NEW: Fire has been contained ...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2016/01/01/middleeast/...</td>\n",
       "      <td>482</td>\n",
       "      <td>[story, highlight, new, fire, contained, guest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Super PACs backing Cruz to launch TV ad blitz</td>\n",
       "      <td>Published 8:36 PM EST, Thu December 31, 2015</td>\n",
       "      <td>Story highlights Ads supporting Cruz set to ai...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>https://edition.cnn.com/2015/12/31/politics/cr...</td>\n",
       "      <td>1428</td>\n",
       "      <td>[story, highlight, ad, supporting, cruz, set, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Headline  \\\n",
       "0   1  China says it’s building new homegrown aircraf...   \n",
       "1   2  Hillary Clinton emails: Kissinger, Photoshop a...   \n",
       "2   3                         How the stars rang in 2016   \n",
       "3   4  Smoke still wafting from Dubai’s luxury Addres...   \n",
       "4   5      Super PACs backing Cruz to launch TV ad blitz   \n",
       "\n",
       "                                           Date  \\\n",
       "0      Updated 1:09 PM EST, Fri January 1, 2016   \n",
       "1    Updated 9:34 PM EST, Thu December 31, 2015   \n",
       "2    Published 9:04 AM EST, Fri January 1, 2016   \n",
       "3      Updated 4:55 PM EST, Fri January 1, 2016   \n",
       "4  Published 8:36 PM EST, Thu December 31, 2015   \n",
       "\n",
       "                                                Text Organization  \\\n",
       "0  Story highlights The U.S. military has long be...          CNN   \n",
       "1  Story highlights The State Department released...          CNN   \n",
       "2  Story highlights Some stars hit exotic locatio...          CNN   \n",
       "3  Story highlights NEW: Fire has been contained ...          CNN   \n",
       "4  Story highlights Ads supporting Cruz set to ai...          CNN   \n",
       "\n",
       "                                                Link  Cluster  \\\n",
       "0  https://edition.cnn.com/2015/12/31/asia/china-...      619   \n",
       "1  https://edition.cnn.com/2015/12/31/politics/cl...       -1   \n",
       "2  https://edition.cnn.com/2016/01/01/entertainme...       -1   \n",
       "3  https://edition.cnn.com/2016/01/01/middleeast/...      482   \n",
       "4  https://edition.cnn.com/2015/12/31/politics/cr...     1428   \n",
       "\n",
       "                                        Text_cleaned  \n",
       "0  [story, highlight, military, long, believed, c...  \n",
       "1  [story, highlight, state, department, released...  \n",
       "2  [story, highlight, star, hit, exotic, location...  \n",
       "3  [story, highlight, new, fire, contained, guest...  \n",
       "4  [story, highlight, ad, supporting, cruz, set, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"Text_cleaned\"] = df_final[\"Text_cleaned\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446967\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary from the documents\n",
    "dictionary = corpora.Dictionary(df_final[\"Text_cleaned\"])\n",
    "\n",
    "# Create a corpus from the documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df_final[\"Text_cleaned\"]]\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)\n",
    "\n",
    "pyLDAvis.save_html(vis, 'lda_visualization.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model_2 = LdaModel(corpus, num_topics=8, id2word=dictionary, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.enable_notebook()\n",
    "#vis_2 = pyLDAvis.gensim_models.prepare(lda_model_2, corpus, dictionary)\n",
    "#pyLDAvis.display(vis_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.enable_notebook()\n",
    "#vis_3 = pyLDAvis.gensim_models.prepare(lda_model_3, corpus, dictionary)\n",
    "#pyLDAvis.display(vis_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model_5 = LdaModel(corpus, num_topics=2000, id2word=dictionary, passes=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
